{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd0b0285039934b2c45504955ea823010382f959d5d9978cc1be0d4284abc2126ee",
   "display_name": "Python 3.9.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "b0285039934b2c45504955ea823010382f959d5d9978cc1be0d4284abc2126ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file = os.path.abspath('')\n",
    "data = np.genfromtxt('./dataR2.csv', delimiter=',', skip_header=True)\n",
    "# mieszam sobie zbiór, bo... bo mogę\n",
    "np.random.shuffle(data)\n",
    "# height to de facto liczba badań\n",
    "height, _ = data.shape\n",
    "# liczba zbiorów testowych, liczba zbiorów treningowych\n",
    "# potem się okaże, że wystarczy jedno z nich, ale nie chce mi się już używać korektora\n",
    "n_test, n_train = round(0.2*height), height-round(0.2*height)\n",
    "# sprawdzam, czy nie potknąłem się o zaokrąglenie, ale pewnie jakby wziąć pod uwagę dokładność numeryczną, to poniższy krok prawdopodobnie nie ma sensu\n",
    "# (sztuka dla sztuki, jak paw dumnie prezentuje swój ogon, tak jak dumnie prezentuję znajomość niesamowicie skomplikowanej składni języka Python)\n",
    "# <owacje>\n",
    "assert n_test+n_train==height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove broken data (needles if skip_header=True)\n",
    "filtered = []\n",
    "for row in data:\n",
    "    if np.isnan(np.sum(row)):\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(93, 9) (93,)\n(93, 10) (23, 10) 93 23\n"
     ]
    }
   ],
   "source": [
    "train_set = data[:n_train,:]\n",
    "train_x, train_y = train_set[:,:-1], train_set[:,-1:].squeeze()\n",
    "print(train_x.shape, train_y.shape)\n",
    "test_set=data[n_train:,:]\n",
    "test_x, test_y = test_set[:,:-1], test_set[:,-1:].squeeze()\n",
    "print(train_set.shape, test_set.shape, n_train, n_test)\n",
    "# nie ma potrzeby normalizacji train_y i test_y do {0,1}, ponieważ macierz predykcji wskazuje na prawdopodobieństwo wystąpienia kolejnych klas\n",
    "# (w naszym przypadku to 1 i 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0, ).fit(train_x, train_y)\n",
    "# podobno liblinear is good for small datasets, a ja nie mam zamiaru się z tym kłucić"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1. 2.]\n              precision    recall  f1-score   support\n\n         1.0       0.53      0.89      0.67         9\n         2.0       0.88      0.50      0.64        14\n\n    accuracy                           0.65        23\n   macro avg       0.70      0.69      0.65        23\nweighted avg       0.74      0.65      0.65        23\n\n***\nOdp.: Trafność decyzji wynosi 0.652, a czułość wyniosła 0.694.\n"
     ]
    }
   ],
   "source": [
    "print(model.classes_)\n",
    "# ważne!\n",
    "# w naszym przypadku są dwie klasy (liczba kolumn w macierzy predict_proba)\n",
    "# model.predict bierze pod uwagę macierz n x 2, gdzie pierwsza kolumna to prawdopodobieństwo pierwszej klasy (1),\n",
    "# a druga kolumna to prawd drugiej klasy (2). Czyli (wg mnie) próg odcięcia tutaj wynosi 0.5\n",
    "pred_y = model.predict(test_x)\n",
    "cls_report = classification_report(test_y, pred_y, output_dict=False)\n",
    "cls_report_dict = classification_report(test_y, pred_y, output_dict=True)\n",
    "print(cls_report)\n",
    "trafnosc_predykcji = cls_report_dict.keys()\n",
    "trafnosc_decyzji = round(cls_report_dict['macro avg']['f1-score'], 3)\n",
    "# podobno recall to jest czułość\n",
    "czulosc = round(cls_report_dict['macro avg']['recall'], 3)\n",
    "print('***')\n",
    "print(f'Odp.: Trafność decyzji wynosi {trafnosc_decyzji}, a czułość wyniosła {czulosc}.')"
   ]
  }
 ]
}